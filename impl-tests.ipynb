{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f057d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.distributions.categorical import Categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af15a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 128\n",
    "m = 64\n",
    "k = 3\n",
    "o = 3\n",
    "\n",
    "gamma = 0.1\n",
    "tau = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6566e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = nn.Parameter(torch.Tensor(n * n))\n",
    "D = nn.Parameter(torch.Tensor(n * n, m))\n",
    "F = nn.Parameter(torch.Tensor(m))\n",
    "H = nn.Parameter(torch.Tensor(m, n * n))\n",
    "\n",
    "W_in_1 = nn.Parameter(torch.Tensor(n, k))\n",
    "W_in_2 = nn.Parameter(torch.Tensor(m, k))\n",
    "\n",
    "with torch.no_grad():\n",
    "    C.normal_(std = 1. / np.sqrt(n * n))\n",
    "    D.normal_(std = 1. / np.sqrt(n * n))\n",
    "    F.normal_(std = 1. / np.sqrt(m))\n",
    "    H.normal_(std = 1. / np.sqrt(m))\n",
    "    W_in_1.uniform_(-1. / np.sqrt(k), 1. / np.sqrt(k))\n",
    "    W_in_2.uniform_(-1. / np.sqrt(k), 1. / np.sqrt(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee585706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4506],\n",
       "         [-0.3785],\n",
       "         [-1.2354],\n",
       "         [ 0.0955],\n",
       "         [-0.6702],\n",
       "         [-0.3804],\n",
       "         [ 1.1943],\n",
       "         [ 0.8052],\n",
       "         [-0.3001],\n",
       "         [-0.0360],\n",
       "         [-0.1137],\n",
       "         [-0.1782],\n",
       "         [ 1.1300],\n",
       "         [-0.6214],\n",
       "         [ 0.2712],\n",
       "         [-0.2148],\n",
       "         [-0.3060],\n",
       "         [-0.2194],\n",
       "         [ 0.5025],\n",
       "         [-0.1934],\n",
       "         [ 0.9057],\n",
       "         [-0.3288],\n",
       "         [-0.6845],\n",
       "         [-0.1833],\n",
       "         [-0.5975],\n",
       "         [ 0.3016],\n",
       "         [-0.8432],\n",
       "         [ 0.3582],\n",
       "         [ 0.5525],\n",
       "         [ 0.0683],\n",
       "         [ 0.0277],\n",
       "         [ 0.6777],\n",
       "         [-0.3001],\n",
       "         [-1.1370],\n",
       "         [ 1.0836],\n",
       "         [-0.5642],\n",
       "         [-0.8647],\n",
       "         [ 1.0996],\n",
       "         [-0.3495],\n",
       "         [ 1.0084],\n",
       "         [ 1.2731],\n",
       "         [-0.6271],\n",
       "         [-1.0080],\n",
       "         [ 0.3298],\n",
       "         [ 1.0204],\n",
       "         [-0.4690],\n",
       "         [ 0.4809],\n",
       "         [-0.2664],\n",
       "         [ 0.7098],\n",
       "         [ 0.9914],\n",
       "         [ 0.2645],\n",
       "         [ 1.1866],\n",
       "         [ 1.0953],\n",
       "         [ 0.6207],\n",
       "         [ 1.3622],\n",
       "         [-0.6747],\n",
       "         [-0.1990],\n",
       "         [-0.8555],\n",
       "         [ 0.3980],\n",
       "         [-0.9087],\n",
       "         [-0.1871],\n",
       "         [-0.7802],\n",
       "         [-0.2952],\n",
       "         [-1.0160],\n",
       "         [-0.4255],\n",
       "         [ 0.3096],\n",
       "         [ 0.7684],\n",
       "         [ 0.2095],\n",
       "         [ 0.2166],\n",
       "         [ 0.1577],\n",
       "         [ 0.6857],\n",
       "         [ 0.6698],\n",
       "         [-0.7262],\n",
       "         [-0.1312],\n",
       "         [-0.6234],\n",
       "         [ 0.2762],\n",
       "         [ 0.9378],\n",
       "         [-0.1319],\n",
       "         [ 0.3400],\n",
       "         [ 0.9096],\n",
       "         [ 0.3922],\n",
       "         [-0.7051],\n",
       "         [ 0.5509],\n",
       "         [ 0.4013],\n",
       "         [ 0.7404],\n",
       "         [-0.0726],\n",
       "         [ 1.0178],\n",
       "         [ 0.7775],\n",
       "         [-0.1485],\n",
       "         [-0.5341],\n",
       "         [ 0.3304],\n",
       "         [-0.6698],\n",
       "         [ 0.7158],\n",
       "         [-0.8904],\n",
       "         [-0.0962],\n",
       "         [ 0.3281],\n",
       "         [-0.0473],\n",
       "         [-0.3800],\n",
       "         [-0.1184],\n",
       "         [-0.6941],\n",
       "         [ 0.5061],\n",
       "         [-0.5581],\n",
       "         [-0.1215],\n",
       "         [ 0.1331],\n",
       "         [-0.3299],\n",
       "         [-1.2978],\n",
       "         [-0.5215],\n",
       "         [-0.9411],\n",
       "         [-0.4882],\n",
       "         [-0.0349],\n",
       "         [ 0.1760],\n",
       "         [-0.5796],\n",
       "         [-0.1821],\n",
       "         [ 0.2994],\n",
       "         [ 1.3410],\n",
       "         [-0.3657],\n",
       "         [ 0.7303],\n",
       "         [-0.5364],\n",
       "         [ 0.8673],\n",
       "         [ 0.4883],\n",
       "         [ 0.2981],\n",
       "         [ 0.0593],\n",
       "         [ 0.3758],\n",
       "         [-0.1118],\n",
       "         [-0.7394],\n",
       "         [-1.0819],\n",
       "         [-0.5607],\n",
       "         [ 0.0910]], grad_fn=<AddBackward0>),\n",
       " (tensor([[ 0.4506],\n",
       "          [-0.3785],\n",
       "          [-1.2354],\n",
       "          [ 0.0955],\n",
       "          [-0.6702],\n",
       "          [-0.3804],\n",
       "          [ 1.1943],\n",
       "          [ 0.8052],\n",
       "          [-0.3001],\n",
       "          [-0.0360],\n",
       "          [-0.1137],\n",
       "          [-0.1782],\n",
       "          [ 1.1300],\n",
       "          [-0.6214],\n",
       "          [ 0.2712],\n",
       "          [-0.2148],\n",
       "          [-0.3060],\n",
       "          [-0.2194],\n",
       "          [ 0.5025],\n",
       "          [-0.1934],\n",
       "          [ 0.9057],\n",
       "          [-0.3288],\n",
       "          [-0.6845],\n",
       "          [-0.1833],\n",
       "          [-0.5975],\n",
       "          [ 0.3016],\n",
       "          [-0.8432],\n",
       "          [ 0.3582],\n",
       "          [ 0.5525],\n",
       "          [ 0.0683],\n",
       "          [ 0.0277],\n",
       "          [ 0.6777],\n",
       "          [-0.3001],\n",
       "          [-1.1370],\n",
       "          [ 1.0836],\n",
       "          [-0.5642],\n",
       "          [-0.8647],\n",
       "          [ 1.0996],\n",
       "          [-0.3495],\n",
       "          [ 1.0084],\n",
       "          [ 1.2731],\n",
       "          [-0.6271],\n",
       "          [-1.0080],\n",
       "          [ 0.3298],\n",
       "          [ 1.0204],\n",
       "          [-0.4690],\n",
       "          [ 0.4809],\n",
       "          [-0.2664],\n",
       "          [ 0.7098],\n",
       "          [ 0.9914],\n",
       "          [ 0.2645],\n",
       "          [ 1.1866],\n",
       "          [ 1.0953],\n",
       "          [ 0.6207],\n",
       "          [ 1.3622],\n",
       "          [-0.6747],\n",
       "          [-0.1990],\n",
       "          [-0.8555],\n",
       "          [ 0.3980],\n",
       "          [-0.9087],\n",
       "          [-0.1871],\n",
       "          [-0.7802],\n",
       "          [-0.2952],\n",
       "          [-1.0160],\n",
       "          [-0.4255],\n",
       "          [ 0.3096],\n",
       "          [ 0.7684],\n",
       "          [ 0.2095],\n",
       "          [ 0.2166],\n",
       "          [ 0.1577],\n",
       "          [ 0.6857],\n",
       "          [ 0.6698],\n",
       "          [-0.7262],\n",
       "          [-0.1312],\n",
       "          [-0.6234],\n",
       "          [ 0.2762],\n",
       "          [ 0.9378],\n",
       "          [-0.1319],\n",
       "          [ 0.3400],\n",
       "          [ 0.9096],\n",
       "          [ 0.3922],\n",
       "          [-0.7051],\n",
       "          [ 0.5509],\n",
       "          [ 0.4013],\n",
       "          [ 0.7404],\n",
       "          [-0.0726],\n",
       "          [ 1.0178],\n",
       "          [ 0.7775],\n",
       "          [-0.1485],\n",
       "          [-0.5341],\n",
       "          [ 0.3304],\n",
       "          [-0.6698],\n",
       "          [ 0.7158],\n",
       "          [-0.8904],\n",
       "          [-0.0962],\n",
       "          [ 0.3281],\n",
       "          [-0.0473],\n",
       "          [-0.3800],\n",
       "          [-0.1184],\n",
       "          [-0.6941],\n",
       "          [ 0.5061],\n",
       "          [-0.5581],\n",
       "          [-0.1215],\n",
       "          [ 0.1331],\n",
       "          [-0.3299],\n",
       "          [-1.2978],\n",
       "          [-0.5215],\n",
       "          [-0.9411],\n",
       "          [-0.4882],\n",
       "          [-0.0349],\n",
       "          [ 0.1760],\n",
       "          [-0.5796],\n",
       "          [-0.1821],\n",
       "          [ 0.2994],\n",
       "          [ 1.3410],\n",
       "          [-0.3657],\n",
       "          [ 0.7303],\n",
       "          [-0.5364],\n",
       "          [ 0.8673],\n",
       "          [ 0.4883],\n",
       "          [ 0.2981],\n",
       "          [ 0.0593],\n",
       "          [ 0.3758],\n",
       "          [-0.1118],\n",
       "          [-0.7394],\n",
       "          [-1.0819],\n",
       "          [-0.5607],\n",
       "          [ 0.0910]], grad_fn=<AddBackward0>),\n",
       "  tensor([[ 2.0000e-04,  4.7014e-04, -8.0289e-05,  ..., -2.1455e-05,\n",
       "           -9.0103e-05,  2.6742e-04],\n",
       "          [-3.5382e-05,  6.0083e-05, -3.0232e-05,  ..., -8.0541e-05,\n",
       "           -8.5785e-05,  6.8155e-07],\n",
       "          [-1.1654e-04, -3.3879e-05, -7.3852e-05,  ...,  2.7757e-06,\n",
       "            5.5979e-05, -2.6272e-05],\n",
       "          ...,\n",
       "          [-1.4153e-04,  1.1409e-05,  3.4844e-05,  ..., -2.7916e-05,\n",
       "            1.2465e-05, -1.1248e-04],\n",
       "          [ 2.4274e-04, -1.7511e-04,  5.4643e-06,  ...,  1.1924e-04,\n",
       "           -6.8628e-05, -1.4904e-04],\n",
       "          [-2.1934e-04, -1.3877e-05, -1.6186e-05,  ...,  1.5954e-04,\n",
       "            2.8769e-05, -8.2179e-05]], grad_fn=<AddBackward0>),\n",
       "  tensor([[ 5.0787e-03],\n",
       "          [ 3.8116e-04],\n",
       "          [-4.6107e-03],\n",
       "          [ 5.0276e-03],\n",
       "          [ 5.5922e-05],\n",
       "          [ 7.7318e-03],\n",
       "          [-2.7744e-03],\n",
       "          [-2.6420e-03],\n",
       "          [ 6.3482e-03],\n",
       "          [-1.5448e-03],\n",
       "          [-6.4692e-03],\n",
       "          [-7.0395e-03],\n",
       "          [-1.0249e-03],\n",
       "          [-4.1907e-03],\n",
       "          [-3.6257e-03],\n",
       "          [-4.4158e-03],\n",
       "          [ 3.6711e-03],\n",
       "          [-4.1940e-03],\n",
       "          [-1.3768e-03],\n",
       "          [ 1.2577e-03],\n",
       "          [ 2.6194e-03],\n",
       "          [-2.5506e-03],\n",
       "          [ 5.0298e-03],\n",
       "          [-1.8503e-03],\n",
       "          [-2.5236e-03],\n",
       "          [-1.9811e-04],\n",
       "          [-5.6467e-03],\n",
       "          [ 6.3527e-03],\n",
       "          [ 1.2109e-03],\n",
       "          [ 2.0992e-03],\n",
       "          [-1.9626e-03],\n",
       "          [ 4.8295e-04],\n",
       "          [ 2.6057e-03],\n",
       "          [-6.8123e-03],\n",
       "          [ 2.2522e-03],\n",
       "          [-3.8650e-03],\n",
       "          [-3.7434e-03],\n",
       "          [-1.9114e-03],\n",
       "          [-1.0967e-03],\n",
       "          [-3.7384e-07],\n",
       "          [-5.0789e-03],\n",
       "          [-5.4996e-03],\n",
       "          [ 1.8953e-03],\n",
       "          [ 4.3267e-03],\n",
       "          [-2.8088e-03],\n",
       "          [ 2.9807e-03],\n",
       "          [ 2.1737e-03],\n",
       "          [ 2.6573e-03],\n",
       "          [ 3.7367e-03],\n",
       "          [-7.0829e-03],\n",
       "          [ 5.7155e-03],\n",
       "          [-2.6721e-03],\n",
       "          [-4.9751e-03],\n",
       "          [ 6.2903e-03],\n",
       "          [-6.3839e-03],\n",
       "          [-2.4779e-03],\n",
       "          [-1.6202e-03],\n",
       "          [-7.2513e-03],\n",
       "          [ 6.2136e-04],\n",
       "          [ 1.7914e-03],\n",
       "          [ 7.1252e-04],\n",
       "          [-3.3807e-03],\n",
       "          [-3.6090e-03],\n",
       "          [-5.4754e-03]], grad_fn=<AddBackward0>)))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, neur_cnt, astr_cnt, in_size, out_size, gamma=0.1, tau=0.01):\n",
    "        super().__init__()\n",
    "        self.n = neur_cnt\n",
    "        self.m = astr_cnt\n",
    "        self.k = in_size\n",
    "        self.o = out_size\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "\n",
    "        self.C = nn.Parameter(torch.Tensor(self.n * self.n))\n",
    "        self.D = nn.Parameter(torch.Tensor(self.n * self.n, self.m))\n",
    "        self.F = nn.Parameter(torch.Tensor(self.m))\n",
    "        self.H = nn.Parameter(torch.Tensor(self.m, self.n * self.n))\n",
    "\n",
    "        self.W_in_1 = nn.Parameter(torch.Tensor(self.n, self.k))\n",
    "        self.W_in_2 = nn.Parameter(torch.Tensor(self.m, self.k))\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.C.normal_(std = 1. / np.sqrt(self.n * self.n))\n",
    "            self.D.normal_(std = 1. / np.sqrt(self.n * self.n))\n",
    "            self.F.normal_(std = 1. / np.sqrt(self.m))\n",
    "            self.H.normal_(std = 1. / np.sqrt(self.m))\n",
    "            self.W_in_1.uniform_(-1. / np.sqrt(self.k), 1. / np.sqrt(self.k))\n",
    "            self.W_in_2.uniform_(-1. / np.sqrt(self.k), 1. / np.sqrt(self.k))\n",
    "        \n",
    "\n",
    "    def phi(self, x):\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "    def Phi(self, x):\n",
    "        return (self.phi(x) @ self.phi(x).reshape(1, -1)).reshape(-1, 1)\n",
    "\n",
    "    def psi(self, z):\n",
    "        return torch.tanh(z)\n",
    "\n",
    "\n",
    "    def forward(self, I, hidden=None):\n",
    "\n",
    "        if hidden is None:\n",
    "            x, W, z =  (torch.zeros(self.n, 1),\n",
    "                        torch.zeros(self.n, self.n),\n",
    "                        torch.zeros(self.m, 1))\n",
    "        else :\n",
    "            x, W, z = hidden\n",
    "        \n",
    "        x = (1 - self.gamma) * x + self.gamma * W @ self.phi(x) + (self.W_in_1 @ I)\n",
    "        W = (1. - self.gamma) * W + self.gamma * (torch.diag(self.C) @ self.Phi(x) + self.D @ self.psi(z)).reshape(self.n, self.n)\n",
    "        z = (1. - self.gamma * self.tau) * z + self.gamma * self.tau * (torch.diag(self.F) @ self.psi(z) + self.H @ self.Phi(x) + self.W_in_2 @ I)\n",
    "\n",
    "        hidden = (x, W, z)\n",
    "        \n",
    "        return x, hidden\n",
    "    \n",
    "\n",
    "\n",
    "M = Model(neur_cnt=128, astr_cnt=64, in_size=2, out_size=3)\n",
    "\n",
    "I = torch.ones((2, 1))\n",
    "state = None\n",
    "M.forward(I, state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
